<html>
<script>
	window.location.replace("https://xt4d.github.io/id-pose-web/");
</script>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, user-scalable=yes, minimum-scale=1.0, maximum-scale=1.0">
	<link rel="stylesheet" href="css/bulma.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.4/css/academicons.min.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/js/all.min.js"></script>
	<title>ID-Pose</title>
</head>
<body>
	<section>
		<div class="hero-body">
			<div class="container is-max-desktop">
				<div class="columns is-centered">
					<div class="column has-text-centered">
						<h1 class="title is-1 publication-title"><span style="color:DodgerBlue">I</span><span
								style="color:coral">D</span>-<span style="color:olivedrab">Pose</span>: Sparse-view
							Camera Pose Estimation by <span style="color:DodgerBlue">I</span>nverting <span
								style="color:coral">D</span>iffusion Models</h1>
						<div class="is-size-5 publication-authors">
							<!-- Paper authors -->
							<span class="author-block">
								<a href="https://www.cheng.website/" target="_blank">Weihao Cheng</a>,</span>
							<span class="author-block">
								<a href="https://yanpei.me/" target="_blank">Yan-Pei Cao</a>,</span>
							<span class="author-block">
								<a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ" target="_blank">Ying
									Shan</a>
							</span>
						</div>

						<div class="is-size-5 publication-authors">
							<span class="author-block">ARC Lab<br>2023</span>
							<!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
						</div>

						<div class="column has-text-centered">
							<div class="publication-links">
								<!-- ArXiv abstract Link -->
								<span class="link-block">
									<a href="https://arxiv.org/abs/2306.17140" target="_blank"
										class="external-link button is-normal is-rounded is-dark">
										<span class="icon">
											<i class="ai ai-arxiv"></i>
										</span>
										<span>arXiv</span>
									</a>
								</span>

								<!-- Github link -->
								<span class="link-block">
									<a href="https://github.com/xt4d/id-pose" target="_blank"
										class="external-link button is-normal is-rounded is-dark">
										<span class="icon">
											<i class="fab fa-github"></i>
										</span>
										<span>Code</span>
									</a>
								</span>

								<span class="link-block">
									<a href="https://xt4d.github.io/id-pose-web/viewer.html" target="_blank"
										class="external-link button is-normal is-rounded is-dark">
										<span class="icon">
											<i class="fa fa-cube"></i>
										</span>
										<span>Examples</span>
									</a>
								</span>
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
	</section>

	<section class="hero teaser is-light is-small">
		<div class="column has-text-centered">
			<video autoplay="" muted="" loop="" playsinline="" height="100%">
				<source src="https://xt4d.github.io/id-pose-web/res/toyduck.mp4" type="video/mp4">
			</video>
		</div>
	</section>
	<section class="section">
		<div class="container is-max-desktop">
			<div class="is-centered has-text-centered">
				<h2 class="title is-3">Abstract</h2>
				<h2 class="content has-text-justified">
					Given sparse views of a 3D object, estimating their camera poses is a long-standing and intractable problem. Toward this goal, we consider harnessing the pre-trained diffusion model of novel views conditioned on viewpoints (Zero-1-to-3). We present ID-Pose which inverses the denoising diffusion process to estimate the relative pose given two input images. ID-Pose adds a noise to one image, and predicts the noise conditioned on the other image and a hypothesis of the relative pose. The prediction error is used as the minimization objective to find the optimal pose with the gradient descent method. We extend ID-Pose to handle more than two images and estimate each pose with multiple image pairs from triangular relations. ID-Pose requires no training and generalizes to open-world images. We conduct extensive experiments using casually captured photos and rendered images with random viewpoints. The results demonstrate that ID-Pose significantly outperforms state-of-the-art methods.
				</h2>
				<img src="https://xt4d.github.io/id-pose-web/res/teaser.png" width="100%" />
			</div>
		</div>
	</section>

    <section class="section">
		<div class="container is-max-desktop">
			<div class="is-centered has-text-centered">
				<h2 class="title is-3">ðŸ‘‰ Open <a href="https://xt4d.github.io/id-pose-web/viewer.html" target="_blank">Interactive Examples</a>.</h2>
			</div>
		</div>
	</section>

	<section class="section" id="BibTeX">
		<div class="container is-max-desktop content">
			<h2 class="title">BibTeX</h2>
<pre><code>@article{cheng2023id, 
   title={ID-Pose: Sparse-view Camera Pose Estimation by Inverting Diffusion Models}, 
   author={Cheng, Weihao and Cao, Yan-Pei and Shan, Ying}, 
   journal={arXiv preprint arXiv:2306.17140}, 
   year={2023}
}
</code></pre>
		</div>
	</section>

	<footer class="footer">
		<div class="container">
			<div class="container" align="center">
				<div class="column is-centered">
					<div class="content">
						<p>
							ID-Pose Webpage v0.1
						</p>
						<p>
						The template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io" target="_blank">nerfies</a>.
						</p>
					</div>
				</div>
			</div>
		</div>
	</footer>

</body>
</html>